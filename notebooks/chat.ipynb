{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\n",
    "    dotenv_path=\"/Users/tomwattley/App/racing-api-project/racing-api-project/libraries/api-helpers/src/api_helpers/.env\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"/Users/tomwattley/App/racing-api-project/racing-api-project/todays_data.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horse_name</th>\n",
       "      <th>age</th>\n",
       "      <th>horse_sex</th>\n",
       "      <th>draw</th>\n",
       "      <th>headgear</th>\n",
       "      <th>weight_carried</th>\n",
       "      <th>weight_carried_lbs</th>\n",
       "      <th>extra_weight</th>\n",
       "      <th>jockey_claim</th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>...</th>\n",
       "      <th>lay_price_4_place</th>\n",
       "      <th>lay_price_4_depth_place</th>\n",
       "      <th>lay_price_5_place</th>\n",
       "      <th>lay_price_5_depth_place</th>\n",
       "      <th>total_matched_event_place</th>\n",
       "      <th>percent_back_win_book_place</th>\n",
       "      <th>percent_lay_win_book_place</th>\n",
       "      <th>betfair_win_sp</th>\n",
       "      <th>betfair_place_sp</th>\n",
       "      <th>price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Stacey Racey</td>\n",
       "      <td>4</td>\n",
       "      <td>Filly</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8-10</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Pacific Prince</td>\n",
       "      <td>4</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9-6</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>970.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Adace</td>\n",
       "      <td>7</td>\n",
       "      <td>Mare</td>\n",
       "      <td>5.0</td>\n",
       "      <td>cheekpieces</td>\n",
       "      <td>9-2</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>3.95</td>\n",
       "      <td>-1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Wadacre Grace</td>\n",
       "      <td>6</td>\n",
       "      <td>Mare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9-9</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.68</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>12.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>Reignman</td>\n",
       "      <td>4</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8-13</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>Capuchinero</td>\n",
       "      <td>6</td>\n",
       "      <td>Mare</td>\n",
       "      <td>10.0</td>\n",
       "      <td>tongue tie, cheekpieces</td>\n",
       "      <td>9-8</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>Drumstick</td>\n",
       "      <td>4</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>6.0</td>\n",
       "      <td>hood</td>\n",
       "      <td>9-8</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.72</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Romanovich</td>\n",
       "      <td>6</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>4.0</td>\n",
       "      <td>blinkers</td>\n",
       "      <td>9-5</td>\n",
       "      <td>131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>American Treasure</td>\n",
       "      <td>4</td>\n",
       "      <td>Filly</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9-9</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>Racing Country</td>\n",
       "      <td>10</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9-6</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>170.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             horse_name  age horse_sex  draw                 headgear  \\\n",
       "156        Stacey Racey    4     Filly   8.0                     None   \n",
       "408      Pacific Prince    4   Gelding   7.0                     None   \n",
       "700               Adace    7      Mare   5.0              cheekpieces   \n",
       "901       Wadacre Grace    6      Mare   1.0                     None   \n",
       "1277           Reignman    4   Gelding   3.0                     None   \n",
       "1298        Capuchinero    6      Mare  10.0  tongue tie, cheekpieces   \n",
       "1880          Drumstick    4   Gelding   6.0                     hood   \n",
       "1938         Romanovich    6   Gelding   4.0                 blinkers   \n",
       "2819  American Treasure    4     Filly   2.0                     None   \n",
       "3143     Racing Country   10   Gelding   9.0                     None   \n",
       "\n",
       "     weight_carried  weight_carried_lbs  extra_weight  jockey_claim  \\\n",
       "156            8-10                 122           NaN           NaN   \n",
       "408             9-6                 132           NaN           3.0   \n",
       "700             9-2                 128           NaN           NaN   \n",
       "901             9-9                 135           NaN           NaN   \n",
       "1277           8-13                 125           NaN           NaN   \n",
       "1298            9-8                 134           NaN           3.0   \n",
       "1880            9-8                 134           NaN           NaN   \n",
       "1938            9-5                 131           NaN           NaN   \n",
       "2819            9-9                 135           NaN           NaN   \n",
       "3143            9-6                 132           NaN           NaN   \n",
       "\n",
       "     finishing_position  ... lay_price_4_place lay_price_4_depth_place  \\\n",
       "156                None  ...              3.55                     0.0   \n",
       "408                None  ...            970.00                     0.0   \n",
       "700                None  ...              7.60                     0.0   \n",
       "901                None  ...              1.68                    13.0   \n",
       "1277               None  ...              4.60                     3.0   \n",
       "1298               None  ...             12.00                     2.0   \n",
       "1880               None  ...              1.72                     4.0   \n",
       "1938               None  ...              4.10                     4.0   \n",
       "2819               None  ...              3.80                     0.0   \n",
       "3143               None  ...               NaN                     NaN   \n",
       "\n",
       "      lay_price_5_place  lay_price_5_depth_place  total_matched_event_place  \\\n",
       "156                3.65                      0.0                      226.0   \n",
       "408                 NaN                      NaN                      226.0   \n",
       "700                7.80                      2.0                      218.0   \n",
       "901                1.70                     12.0                      218.0   \n",
       "1277               4.70                      0.0                      226.0   \n",
       "1298              14.00                      5.0                      218.0   \n",
       "1880               1.76                      4.0                      218.0   \n",
       "1938               4.20                      6.0                      218.0   \n",
       "2819               3.90                      1.0                      226.0   \n",
       "3143                NaN                      NaN                      226.0   \n",
       "\n",
       "     percent_back_win_book_place percent_lay_win_book_place betfair_win_sp  \\\n",
       "156                        310.0                      280.0          10.00   \n",
       "408                        310.0                      280.0         140.00   \n",
       "700                        310.0                      280.0          19.00   \n",
       "901                        310.0                      280.0           3.70   \n",
       "1277                       310.0                      280.0          12.50   \n",
       "1298                       310.0                      280.0          30.00   \n",
       "1880                       310.0                      280.0           3.75   \n",
       "1938                       310.0                      280.0          14.00   \n",
       "2819                       310.0                      280.0           9.20   \n",
       "3143                       310.0                      280.0         170.00   \n",
       "\n",
       "     betfair_place_sp  price_change  \n",
       "156              2.74         -0.91  \n",
       "408               NaN          1.29  \n",
       "700              3.95         -1.26  \n",
       "901               NaN         -0.36  \n",
       "1277             3.45          2.00  \n",
       "1298             7.00          5.36  \n",
       "1880             1.51         -8.15  \n",
       "1938              NaN          4.49  \n",
       "2819             2.60          5.80  \n",
       "3143            46.00          7.10  \n",
       "\n",
       "[10 rows x 118 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['data_type'] == 'today') & (df['race_time'] == '2025-07-09 20:25:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['horse_name',\n",
       " 'age',\n",
       " 'horse_sex',\n",
       " 'draw',\n",
       " 'headgear',\n",
       " 'weight_carried',\n",
       " 'weight_carried_lbs',\n",
       " 'extra_weight',\n",
       " 'jockey_claim',\n",
       " 'finishing_position',\n",
       " 'total_distance_beaten',\n",
       " 'industry_sp',\n",
       " 'official_rating',\n",
       " 'in_play_high',\n",
       " 'in_play_low',\n",
       " 'in_race_comment',\n",
       " 'tf_comment',\n",
       " 'rp_comment',\n",
       " 'tfr_view',\n",
       " 'race_id',\n",
       " 'horse_id',\n",
       " 'jockey_id',\n",
       " 'trainer_id',\n",
       " 'owner_id',\n",
       " 'sire_id',\n",
       " 'dam_id',\n",
       " 'unique_id',\n",
       " 'race_time',\n",
       " 'race_date',\n",
       " 'race_title',\n",
       " 'race_type',\n",
       " 'race_class',\n",
       " 'distance',\n",
       " 'distance_yards',\n",
       " 'distance_meters',\n",
       " 'distance_kilometers',\n",
       " 'conditions',\n",
       " 'going',\n",
       " 'number_of_runners',\n",
       " 'hcap_range',\n",
       " 'age_range',\n",
       " 'surface',\n",
       " 'total_prize_money',\n",
       " 'first_place_prize_money',\n",
       " 'winning_time',\n",
       " 'time_seconds',\n",
       " 'relative_time',\n",
       " 'relative_to_standard',\n",
       " 'country',\n",
       " 'main_race_comment',\n",
       " 'meeting_id',\n",
       " 'course_id',\n",
       " 'course',\n",
       " 'dam',\n",
       " 'sire',\n",
       " 'trainer',\n",
       " 'jockey',\n",
       " 'ts',\n",
       " 'rpr',\n",
       " 'tfr',\n",
       " 'tfig',\n",
       " 'data_type',\n",
       " 'todays_betfair_selection_id',\n",
       " 'status',\n",
       " 'market_id_win',\n",
       " 'total_matched_win',\n",
       " 'back_price_1_win',\n",
       " 'back_price_1_depth_win',\n",
       " 'back_price_2_win',\n",
       " 'back_price_2_depth_win',\n",
       " 'back_price_3_win',\n",
       " 'back_price_3_depth_win',\n",
       " 'back_price_4_win',\n",
       " 'back_price_4_depth_win',\n",
       " 'back_price_5_win',\n",
       " 'back_price_5_depth_win',\n",
       " 'lay_price_1_win',\n",
       " 'lay_price_1_depth_win',\n",
       " 'lay_price_2_win',\n",
       " 'lay_price_2_depth_win',\n",
       " 'lay_price_3_win',\n",
       " 'lay_price_3_depth_win',\n",
       " 'lay_price_4_win',\n",
       " 'lay_price_4_depth_win',\n",
       " 'lay_price_5_win',\n",
       " 'lay_price_5_depth_win',\n",
       " 'total_matched_event_win',\n",
       " 'percent_back_win_book_win',\n",
       " 'percent_lay_win_book_win',\n",
       " 'market_place',\n",
       " 'market_id_place',\n",
       " 'total_matched_place',\n",
       " 'back_price_1_place',\n",
       " 'back_price_1_depth_place',\n",
       " 'back_price_2_place',\n",
       " 'back_price_2_depth_place',\n",
       " 'back_price_3_place',\n",
       " 'back_price_3_depth_place',\n",
       " 'back_price_4_place',\n",
       " 'back_price_4_depth_place',\n",
       " 'back_price_5_place',\n",
       " 'back_price_5_depth_place',\n",
       " 'lay_price_1_place',\n",
       " 'lay_price_1_depth_place',\n",
       " 'lay_price_2_place',\n",
       " 'lay_price_2_depth_place',\n",
       " 'lay_price_3_place',\n",
       " 'lay_price_3_depth_place',\n",
       " 'lay_price_4_place',\n",
       " 'lay_price_4_depth_place',\n",
       " 'lay_price_5_place',\n",
       " 'lay_price_5_depth_place',\n",
       " 'total_matched_event_place',\n",
       " 'percent_back_win_book_place',\n",
       " 'percent_lay_win_book_place',\n",
       " 'betfair_win_sp',\n",
       " 'betfair_place_sp',\n",
       " 'price_change']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\n",
    "\n",
    "['horse_name',\n",
    " 'age',\n",
    " 'horse_sex',\n",
    " 'draw',\n",
    " 'headgear',\n",
    " 'weight_carried',\n",
    " 'weight_carried_lbs',\n",
    " 'extra_weight',\n",
    " 'jockey_claim',\n",
    " 'finishing_position',\n",
    " 'total_distance_beaten',\n",
    " 'industry_sp',\n",
    " 'official_rating',\n",
    " 'in_play_high',\n",
    " 'in_play_low',\n",
    " 'in_race_comment',\n",
    " 'tf_comment',\n",
    " 'rp_comment',\n",
    " 'tfr_view',\n",
    " 'race_id',\n",
    " 'horse_id',\n",
    " 'jockey_id',\n",
    " 'trainer_id',\n",
    " 'owner_id',\n",
    " 'sire_id',\n",
    " 'dam_id',\n",
    " 'unique_id',\n",
    " 'race_time',\n",
    " 'race_date',\n",
    " 'race_title',\n",
    " 'race_type',\n",
    " 'race_class',\n",
    " 'distance',\n",
    " 'distance_yards',\n",
    " 'distance_meters',\n",
    " 'distance_kilometers',\n",
    " 'conditions',\n",
    " 'going',\n",
    " 'number_of_runners',\n",
    " 'hcap_range',\n",
    " 'age_range',\n",
    " 'surface',\n",
    " 'total_prize_money',\n",
    " 'first_place_prize_money',\n",
    " 'winning_time',\n",
    " 'time_seconds',\n",
    " 'relative_time',\n",
    " 'relative_to_standard',\n",
    " 'country',\n",
    " 'main_race_comment',\n",
    " 'meeting_id',\n",
    " 'course_id',\n",
    " 'course',\n",
    " 'dam',\n",
    " 'sire',\n",
    " 'trainer',\n",
    " 'jockey',\n",
    " 'ts',\n",
    " 'rpr',\n",
    " 'tfr',\n",
    " 'tfig',\n",
    " 'data_type',\n",
    " 'betfair_win_sp',\n",
    " 'betfair_place_sp',\n",
    " 'price_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for structured data\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class HorseComment(BaseModel):\n",
    "    horse_name: str\n",
    "    main_race_comment: Optional[str] = None\n",
    "    race_provider_one: Optional[str] = None\n",
    "    race_provider_two: Optional[str] = None\n",
    "    betfair_win_sp: Optional[float] = None\n",
    "    finishing_position: Optional[int] = None\n",
    "\n",
    "class HorseComments(BaseModel):\n",
    "    horse_comments: list[HorseComment]\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        # Allow arbitrary types for compatibility\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "def get_comments(horse_name, df):\n",
    "    horse_data = df[(df['horse_name'] == horse_name) & (df['data_type'] == 'historical')].sort_values(\n",
    "        by='race_date'\n",
    "    ).head(3)\n",
    "    comments = []\n",
    "    for index, row in horse_data.iterrows():\n",
    "        comment = HorseComment(\n",
    "            horse_name=row['horse_name'],\n",
    "            date=row['race_date'],\n",
    "            comment=row['comment'],\n",
    "            race_type=row['race_type'],\n",
    "            position=row['position']\n",
    "        )\n",
    "        comments.append(comment)\n",
    "    return HorseComments(horse_comments=comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}\n",
    "\n",
    "\n",
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    \n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state'] \n",
    "    \n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "    \n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is Lance. I am sad!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "# llm = ChatOllama(model=\"deepseek-r1:14b\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ---- LangChain OpenAI Chat Model Example ----\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# # Create a ChatOpenAI model\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# result = model.invoke(messages)\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# print(f\"Answer from Google: {result.content}\")\u001b[39;00m\n\u001b[32m     50\u001b[39m model = ChatOllama(model=\u001b[33m\"\u001b[39m\u001b[33mdeepseek-r1:14b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:800\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    795\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     **kwargs: Any,\n\u001b[32m    799\u001b[39m ) -> ChatResult:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    803\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m    804\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    805\u001b[39m         message=AIMessage(\n\u001b[32m    806\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    811\u001b[39m         generation_info=generation_info,\n\u001b[32m    812\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:735\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    727\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    728\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    732\u001b[39m     **kwargs: Any,\n\u001b[32m    733\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    734\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:822\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m    816\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    817\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m    818\u001b[39m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    819\u001b[39m     **kwargs: Any,\n\u001b[32m    820\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m    821\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:721\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    720\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/ollama/_client.py:165\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m      \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_client.py:868\u001b[39m, in \u001b[36mClient.stream\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[33;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m \u001b[33;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    855\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    856\u001b[39m     method=method,\n\u001b[32m    857\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    866\u001b[39m     extensions=extensions,\n\u001b[32m    867\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    # SystemMessage(\n",
    "    #     content=\"\"\"\n",
    "    #             You are a horse racing expert and you have some data about a horses past performances, you\n",
    "    #             want to know if there is a value bet in the race, you always have a trusty flow diagram and checklist\n",
    "    #             to go through to ensure you are making the right decision. You first look to define the category. The\n",
    "    #             categories you look to identify are the following, 1. horses 3 year old or greater where 3 or more horses are in form,\n",
    "    #             older horses where 2 or less horses are in form, 3. 3 year olds where 2 or more horses are in form, 4. 3 year olds\n",
    "    #             how competitive a race is\n",
    "    #             this is defined by the number of horses that are in current form, you aim to categorise the races into 4 tyoes\n",
    "    #             1. Competitive - 5 or more horses in form, 2. Average - 3-4 horses in form, 3. Uncompetitive - 2 or less horses in form\n",
    "    #             4 minefeilds - 0 horses in form, this helps you to understand how to move on to the next step of your decision making process.\n",
    "    #             where you look at todays conditions and how you think the runners will perform under these conditions, these are race distance and going (surface conditions\n",
    "    #             \"\"\"\n",
    "    # ),\n",
    "    HumanMessage(content=\"What is 81 divided by 9?\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ---- LangChain OpenAI Chat Model Example ----\n",
    "\n",
    "# # Create a ChatOpenAI model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# # Invoke the model with messages\n",
    "# result = model.invoke(messages)\n",
    "# print(f\"Answer from OpenAI: {result.content}\")\n",
    "\n",
    "\n",
    "# ---- Anthropic Chat Model Example ----\n",
    "\n",
    "# Create a Anthropic model\n",
    "# Anthropic models: https://docs.anthropic.com/en/docs/models-overview\n",
    "# model = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "# result = model.invoke(messages)\n",
    "# print(f\"Answer from Anthropic: {result.content}\")\n",
    "\n",
    "\n",
    "# ---- Google Chat Model Example ----\n",
    "\n",
    "# https://console.cloud.google.com/gen-app-builder/engines\n",
    "# https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "# model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# result = model.invoke(messages)\n",
    "# print(f\"Answer from Google: {result.content}\")\n",
    "\n",
    "\n",
    "model = ChatOllama(model=\"deepseek-r1:14b\")\n",
    "result = model.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, the best place to see Orcas in the US is generally considered to be the **Salish Sea**, which encompasses the waters around **Washington State and British Columbia, Canada**.\\n\\nWithin the Salish Sea, here are some more specific areas and factors to consider:\\n\\n*   **Puget Sound, Washington:** The San Juan Islands, located in northern Puget Sound, are a prime location. Whale watching tours frequently depart from towns like Friday Harbor and Anacortes. The Southern Resident orca population is often spotted here.\\n*   ** Johnstone Strait, British Columbia:** While in Canada, this strait is part of the Salish Sea and is well-known for orca sightings, especially during the summer months.\\n\\nWould you like more information on the best time of year to visit, specific tour operators, or any other details about Orca sightings?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--83b1c256-c784-4546-8182-09b365f5a66d-0', usage_metadata={'input_tokens': 42, 'output_tokens': 175, 'total_tokens': 217, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]\n",
    "\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='b838600f-3c11-4714-a50f-2e5346b437e9'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='d48af662-28a2-459e-83b0-28ca44a54e9b'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='acef7efa-f034-4a0f-9e93-ae36aced37ac')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (649778b4-e7b1-4ebd-8cf0-59c48f2b476e)\n",
      " Call ID: 649778b4-e7b1-4ebd-8cf0-59c48f2b476e\n",
      "  Args:\n",
      "    a: 2.0\n",
      "    b: 3.0\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Pydantic models for structured data\n",
    "class HorseComment(BaseModel):\n",
    "    \"\"\"Individual comment about a horse\"\"\"\n",
    "    horse_name: str\n",
    "    date: datetime\n",
    "    comment: str\n",
    "    race_type: Optional[str] = None\n",
    "    position: Optional[int] = None\n",
    "    \n",
    "    class Config:\n",
    "        # Allow arbitrary types for compatibility\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "class PerformanceAnalysis(BaseModel):\n",
    "    \"\"\"Structured performance analysis result\"\"\"\n",
    "    form_status: Literal[\"Good Form\", \"Poor Form\", \"Mixed Form\", \"Insufficient Data\"]\n",
    "    confidence_score: float = Field(ge=0.0, le=10.0, description=\"Confidence from 0-10\")\n",
    "    analysis: str = Field(description=\"Detailed analysis text\")\n",
    "    key_evidence: List[str] = Field(default_factory=list, description=\"Supporting evidence points\")\n",
    "    trends: List[str] = Field(default_factory=list, description=\"Notable trends or patterns\")\n",
    "    \n",
    "    @field_validator('confidence_score')\n",
    "    def validate_confidence(cls, v):\n",
    "        return max(0.0, min(10.0, v))\n",
    "\n",
    "class WorkflowState(BaseModel):\n",
    "    \"\"\"Main state that flows through the workflow\"\"\"\n",
    "    horse_name: str\n",
    "    raw_dataset: pd.DataFrame\n",
    "    filtered_comments: List[HorseComment] = Field(default_factory=list)\n",
    "    performance_analysis: Optional[PerformanceAnalysis] = None\n",
    "    error_message: Optional[str] = None\n",
    "    metadata: dict = Field(default_factory=dict)\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True  # For pandas DataFrame\n",
    "\n",
    "# Node 1: Filter and validate data\n",
    "def filter_horse_data(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Filter the dataset and convert to structured HorseComment objects\"\"\"\n",
    "    try:\n",
    "        horse_name = state.horse_name\n",
    "        dataset = state.raw_dataset\n",
    "        \n",
    "        # Filter data for the specific horse\n",
    "        horse_data = dataset[dataset['horse_name'] == horse_name].copy()\n",
    "        \n",
    "        if horse_data.empty:\n",
    "            return WorkflowState(\n",
    "                **state.dict(),\n",
    "                error_message=f\"No data found for horse: {horse_name}\"\n",
    "            )\n",
    "        \n",
    "        # Sort by date to get most recent comments first\n",
    "        if 'date' in horse_data.columns:\n",
    "            horse_data = horse_data.sort_values('date', ascending=False)\n",
    "        \n",
    "        # Convert to structured HorseComment objects\n",
    "        filtered_comments = []\n",
    "        for _, row in horse_data.iterrows():\n",
    "            try:\n",
    "                comment = HorseComment(\n",
    "                    horse_name=row['horse_name'],\n",
    "                    date=pd.to_datetime(row['date']) if 'date' in row else datetime.now(),\n",
    "                    comment=row.get('comments', row.get('comment', '')),\n",
    "                    race_type=row.get('race_type'),\n",
    "                    position=row.get('position')\n",
    "                )\n",
    "                filtered_comments.append(comment)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping invalid row: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Update metadata\n",
    "        metadata = {\n",
    "            **state.metadata,\n",
    "            \"total_comments\": len(filtered_comments),\n",
    "            \"date_range\": {\n",
    "                \"earliest\": min(c.date for c in filtered_comments) if filtered_comments else None,\n",
    "                \"latest\": max(c.date for c in filtered_comments) if filtered_comments else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return WorkflowState(\n",
    "            **state.model_dump(),\n",
    "            filtered_comments=filtered_comments,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        return WorkflowState(\n",
    "            **state.model_dump(),\n",
    "            error_message=f\"Error filtering data: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Node 2: Analyze performance with structured output\n",
    "def analyze_performance(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Use LLM to analyze horse performance and return structured analysis\"\"\"\n",
    "    \n",
    "    if state.error_message:\n",
    "        return state\n",
    "    \n",
    "    if not state.filtered_comments:\n",
    "        return WorkflowState(\n",
    "            **state.model_dump(),\n",
    "            performance_analysis=PerformanceAnalysis(\n",
    "                form_status=\"Insufficient Data\",\n",
    "                confidence_score=0.0,\n",
    "                analysis=\"No comments available for analysis\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        # Initialize LLM\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "        \n",
    "        # Create structured prompt\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"horse_name\", \"comments\", \"total_comments\"],\n",
    "            template=\"\"\"\n",
    "            You are an expert horse racing analyst. Analyze the following comments about {horse_name} and provide a structured assessment.\n",
    "\n",
    "            Total comments analyzed: {total_comments}\n",
    "            Comments (most recent first):\n",
    "            {comments}\n",
    "\n",
    "            Please provide your analysis in the following structured format:\n",
    "\n",
    "            FORM_STATUS: [Good Form/Poor Form/Mixed Form]\n",
    "            CONFIDENCE: [number from 1-10]\n",
    "            ANALYSIS: [Your detailed analysis in 2-3 sentences]\n",
    "            KEY_EVIDENCE: [List 2-3 key pieces of evidence, separated by |]\n",
    "            TRENDS: [List 1-2 notable trends, separated by |]\n",
    "\n",
    "            Be concise but thorough. Focus on recent performance indicators.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Prepare comments text with structured data\n",
    "        comments_text = \"\"\n",
    "        for i, comment in enumerate(state.filtered_comments[:10]):  # Limit to 10 most recent\n",
    "            date_str = comment.date.strftime(\"%Y-%m-%d\")\n",
    "            position_str = f\" (Position: {comment.position})\" if comment.position else \"\"\n",
    "            race_type_str = f\" [{comment.race_type}]\" if comment.race_type else \"\"\n",
    "            comments_text += f\"{i+1}. {date_str}{race_type_str}: {comment.comment}{position_str}\\n\"\n",
    "        \n",
    "        # Generate analysis\n",
    "        prompt = prompt_template.format(\n",
    "            horse_name=state.horse_name,\n",
    "            comments=comments_text,\n",
    "            total_comments=len(state.filtered_comments)\n",
    "        )\n",
    "        \n",
    "        llm_response = llm(prompt)\n",
    "        \n",
    "        # Parse structured response\n",
    "        analysis_data = parse_llm_response(llm_response)\n",
    "        \n",
    "        # Create structured analysis object\n",
    "        performance_analysis = PerformanceAnalysis(\n",
    "            form_status=analysis_data.get(\"form_status\", \"Mixed Form\"),\n",
    "            confidence_score=analysis_data.get(\"confidence\", 5.0),\n",
    "            analysis=analysis_data.get(\"analysis\", \"Analysis unavailable\"),\n",
    "            key_evidence=analysis_data.get(\"key_evidence\", []),\n",
    "            trends=analysis_data.get(\"trends\", [])\n",
    "        )\n",
    "        \n",
    "        return WorkflowState(\n",
    "            **state.dict(),\n",
    "            performance_analysis=performance_analysis\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        return WorkflowState(\n",
    "            **state.dict(),\n",
    "            error_message=f\"Error in performance analysis: {str(e)}\"\n",
    "        )\n",
    "\n",
    "def parse_llm_response(response: str) -> dict:\n",
    "    \"\"\"Parse the structured LLM response into components\"\"\"\n",
    "    result = {\n",
    "        \"form_status\": \"Mixed Form\",\n",
    "        \"confidence\": 5.0,\n",
    "        \"analysis\": \"\",\n",
    "        \"key_evidence\": [],\n",
    "        \"trends\": []\n",
    "    }\n",
    "    \n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('FORM_STATUS:'):\n",
    "            result[\"form_status\"] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('CONFIDENCE:'):\n",
    "            try:\n",
    "                result[\"confidence\"] = float(line.split(':', 1)[1].strip())\n",
    "            except:\n",
    "                pass\n",
    "        elif line.startswith('ANALYSIS:'):\n",
    "            result[\"analysis\"] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('KEY_EVIDENCE:'):\n",
    "            evidence = line.split(':', 1)[1].strip()\n",
    "            result[\"key_evidence\"] = [e.strip() for e in evidence.split('|') if e.strip()]\n",
    "        elif line.startswith('TRENDS:'):\n",
    "            trends = line.split(':', 1)[1].strip()\n",
    "            result[\"trends\"] = [t.strip() for t in trends.split('|') if t.strip()]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Node 3: Format final output\n",
    "def format_output(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Format the final output using structured data\"\"\"\n",
    "    \n",
    "    if state.error_message:\n",
    "        formatted_output = f\"\"\"\n",
    "        {'='*50}\n",
    "        ERROR IN HORSE ANALYSIS\n",
    "        {'='*50}\n",
    "        \n",
    "        Horse: {state.horse_name}\n",
    "        Error: {state.error_message}\n",
    "        \n",
    "        {'='*50}\n",
    "        \"\"\"\n",
    "        return WorkflowState(\n",
    "            **state.dict(),\n",
    "            metadata={**state.metadata, \"formatted_output\": formatted_output}\n",
    "        )\n",
    "    \n",
    "    analysis = state.performance_analysis\n",
    "    if not analysis:\n",
    "        return state\n",
    "    \n",
    "    formatted_output = f\"\"\"\n",
    "    {'='*50}\n",
    "    HORSE PERFORMANCE ANALYSIS\n",
    "    {'='*50}\n",
    "    \n",
    "    Horse: {state.horse_name}\n",
    "    Comments Analyzed: {state.metadata.get('total_comments', 0)}\n",
    "    Date Range: {state.metadata.get('date_range', {}).get('earliest', 'N/A')} to {state.metadata.get('date_range', {}).get('latest', 'N/A')}\n",
    "    \n",
    "    FORM STATUS: {analysis.form_status}\n",
    "    CONFIDENCE SCORE: {analysis.confidence_score}/10\n",
    "    \n",
    "    ANALYSIS:\n",
    "    {analysis.analysis}\n",
    "    \n",
    "    KEY EVIDENCE:\n",
    "    {chr(10).join(f\"â€¢ {evidence}\" for evidence in analysis.key_evidence)}\n",
    "    \n",
    "    TRENDS:\n",
    "    {chr(10).join(f\"â€¢ {trend}\" for trend in analysis.trends)}\n",
    "    \n",
    "    {'='*50}\n",
    "    \"\"\"\n",
    "    \n",
    "    return WorkflowState(\n",
    "        **state.dict(),\n",
    "        metadata={**state.metadata, \"formatted_output\": formatted_output}\n",
    "    )\n",
    "\n",
    "# Create the workflow with Pydantic state\n",
    "def create_horse_analysis_workflow():\n",
    "    \"\"\"Create and return the LangGraph workflow with Pydantic state\"\"\"\n",
    "    \n",
    "    # Create the graph with Pydantic state\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"filter_data\", filter_horse_data)\n",
    "    workflow.add_node(\"analyze_performance\", analyze_performance)\n",
    "    workflow.add_node(\"format_output\", format_output)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.add_edge(\"filter_data\", \"analyze_performance\")\n",
    "    workflow.add_edge(\"analyze_performance\", \"format_output\")\n",
    "    workflow.add_edge(\"format_output\", END)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"filter_data\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Main analysis function with Pydantic validation\n",
    "def analyze_horse_performance(horse_name: str, dataset: pd.DataFrame) -> WorkflowState:\n",
    "    \"\"\"\n",
    "    Analyze horse performance with full Pydantic validation\n",
    "    \n",
    "    Args:\n",
    "        horse_name: Name of the horse to analyze\n",
    "        dataset: DataFrame with columns like 'horse_name', 'comments', 'date'\n",
    "    \n",
    "    Returns:\n",
    "        WorkflowState with structured analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create workflow\n",
    "    app = create_horse_analysis_workflow()\n",
    "    \n",
    "    # Create initial state with validation\n",
    "    initial_state = WorkflowState(\n",
    "        horse_name=horse_name,\n",
    "        raw_dataset=dataset,\n",
    "        metadata={\"workflow_started\": datetime.now().isoformat()}\n",
    "    )\n",
    "    \n",
    "    # Run the workflow\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid row: 1 validation error for HorseComment\n",
      "position\n",
      "  Input should be a finite number [type=finite_number, input_value=nan, input_type=float]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/finite_number\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'error_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mfilter_horse_data\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     82\u001b[39m     metadata = {\n\u001b[32m     83\u001b[39m         **state.metadata,\n\u001b[32m     84\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtotal_comments\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(filtered_comments),\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m         }\n\u001b[32m     89\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WorkflowState(\n\u001b[32m     92\u001b[39m         **state.model_dump(),\n\u001b[32m     93\u001b[39m         filtered_comments=filtered_comments,\n\u001b[32m     94\u001b[39m         metadata=metadata\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: __main__.WorkflowState() got multiple values for keyword argument 'filtered_comments'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m df = pd.DataFrame(sample_data)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Analyze with structured output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m result = \u001b[43manalyze_horse_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThunder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Access structured data\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.performance_analysis:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 316\u001b[39m, in \u001b[36manalyze_horse_performance\u001b[39m\u001b[34m(horse_name, dataset)\u001b[39m\n\u001b[32m    309\u001b[39m initial_state = WorkflowState(\n\u001b[32m    310\u001b[39m     horse_name=horse_name,\n\u001b[32m    311\u001b[39m     raw_dataset=dataset,\n\u001b[32m    312\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mworkflow_started\u001b[39m\u001b[33m\"\u001b[39m: datetime.now().isoformat()}\n\u001b[32m    313\u001b[39m )\n\u001b[32m    315\u001b[39m \u001b[38;5;66;03m# Run the workflow\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2843\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2840\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2841\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2843\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2844\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/App/racing-api-project/racing-api-project/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2533\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2531\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2532\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2533\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2543\u001b[39m loop.after_tick()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mfilter_horse_data\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WorkflowState(\n\u001b[32m     92\u001b[39m         **state.model_dump(),\n\u001b[32m     93\u001b[39m         filtered_comments=filtered_comments,\n\u001b[32m     94\u001b[39m         metadata=metadata\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WorkflowState(\n\u001b[32m     99\u001b[39m         **state.model_dump(),\n\u001b[32m    100\u001b[39m         error_message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError filtering data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m     )\n",
      "\u001b[31mKeyError\u001b[39m: 'error_message'",
      "During task with name 'filter_data' and id '8fa0bb2e-7357-46c3-c441-c03f0f6b053d'"
     ]
    }
   ],
   "source": [
    "sample_data = {\n",
    "    'horse_name': ['Thunder', 'Thunder', 'Lightning', 'Thunder'],\n",
    "    'date': ['2024-01-15', '2024-01-10', '2024-01-12', '2024-01-05'],\n",
    "    'comments': [\n",
    "        'Strong finish in the final furlong, looking fit',\n",
    "        'Struggled with the pace, seemed tired',\n",
    "        'Excellent performance, won by 2 lengths',\n",
    "        'Good training session, responsive to commands'\n",
    "    ],\n",
    "    'position': [2, 8, 1, None],\n",
    "    'race_type': ['Sprint', 'Distance', 'Sprint', 'Training']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "# Analyze with structured output\n",
    "result = analyze_horse_performance(\"Thunder\", df)\n",
    "\n",
    "# Access structured data\n",
    "if result.performance_analysis:\n",
    "    print(f\"Form Status: {result.performance_analysis.form_status}\")\n",
    "    print(f\"Confidence: {result.performance_analysis.confidence_score}\")\n",
    "    print(f\"Evidence: {result.performance_analysis.key_evidence}\")\n",
    "\n",
    "# Print formatted output\n",
    "if \"formatted_output\" in result.metadata:\n",
    "    print(result.metadata[\"formatted_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "racing-api-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
